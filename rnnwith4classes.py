# -*- coding: utf-8 -*-
"""RNNwith4Classes.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ItApYrcHvVV7rSq1L4wXPlv-ZenrAGa0
"""

from google.colab import drive
drive.mount('/content/drive')

!gdown --id 1Lx4s240DQDVIF2Zz7P4_DpuBKu8ELUrY

!ls /content/TestData.zip -al

import zipfile
from google.colab import drive

drive.mount('/content/drive')

!unzip "/content/TestData.zip" -d "/content/TestData"

# coding:utf-8
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import re
import os
from PIL import Image
import glob
import tensorflow as tf

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, LSTM
from tensorflow.keras.preprocessing.image import ImageDataGenerator

csvdata_dir = "/content/TestData/TestData/"

# raw data from the sensor
folder = ["GrippingLeftFaster", "GrippingLeft",  "GrippingOnly", "GrippingWithDiffForce"]


max_dataarraysize = 30052

#df maximum value
#last_line = len(folder[0].iloc[:,-1:])

data_collect = []
label = []

n = 0
k = 10

for index, name in enumerate(folder):
    name = name + "/csvs"
    #print(name)
    dir = csvdata_dir + name
    files = glob.glob(dir + "/*.csv")

    for i, file in enumerate(files):
        csv = pd.read_csv(file, sep = ',', encoding = "UTF-8", error_bad_lines = False, header = None)
        data = np.array(csv, dtype = np.float32)
        if csv.empty:
            print('DataFrame is empty!')        # (198959, 3)
        print(data.shape)

        # (19896, 3)
        for i in range(int(max_dataarraysize)):
          

          #For data_collect shape to be (14000, 3, 10)
          preStack = np.vstack((data[n:k, 0], data[n:k, 1]))
          data_stack= np.vstack((preStack, data[n:k, 2]))
          
          data_collect.append(data_stack)
          #print(data_collect)
          label.append([index])
          #print(label)
          n = n+10
          k = k+10
          #print(n,k)

        n = 0
        k = 10

        #data_collect.append(data_collect)

#data_collect = np.asarray(data_stack)

data_collect = np.asarray(data_collect)
label = np.asarray(label)
label =  tf.keras.utils.to_categorical(label, 4)

print(data_collect.shape)
print(label.shape)
# (14000, 30)

X_train, X_test, y_train, y_test = train_test_split(data_collect, label, test_size=0.2, random_state=2)

X_train = X_train / 255.0
X_test = X_test / 255.0

print((X_test.shape))
print((X_train.shape))
print(y_test.shape)

import tensorflow as tf
from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt
import numpy as np

#necessary libraries, functions, layers, etc.
from sklearn.metrics import classification_report, precision_recall_fscore_support
from keras.preprocessing.image import load_img
from keras.preprocessing.image import img_to_array
from keras.applications.inception_v3 import preprocess_input
from keras.applications.inception_v3 import decode_predictions
from keras.applications.inception_v3 import InceptionV3
from sklearn.model_selection import train_test_split
from IPython.display import Image
from keras.models import Model
from keras.layers import Dense
from keras.layers import Flatten
from os import listdir

from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, LSTM, SimpleRNN, GRU, BatchNormalization
from tensorflow.keras import regularizers

hid_dim = 256
epochs = 100

with tf.distribute.MirroredStrategy().scope():
    model = Sequential()
    # output_shape=(units(=hid_dim),)
    model.add(SimpleRNN(hid_dim, input_shape=X_train.shape[1:], activation = 'relu', dropout=0.01)) 
    model.add(BatchNormalization())
    model.add(Dense(32, activation='relu', kernel_regularizer = tf.keras.regularizers.l1_l2(l1=0.001, l2=0.001)))
    model.add(Dense(y_train.shape[1], activation='softmax', kernel_regularizer = tf.keras.regularizers.l1_l2(l1=0.001, l2=0.001)))
    model.summary()

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

history = model.fit(X_train, y_train, batch_size=1024, epochs=epochs, validation_data=(X_test, y_test))

# summarize history for accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import confusion_matrix

y_pred=model.predict(X_test)

print(y_test.shape)
print(y_pred.shape)

y_pred=np.argmax(y_pred, axis=1)
y_test=np.argmax(y_test, axis=1)
cm = confusion_matrix(y_test, y_pred)
print(cm)

#cm = confusion_matrix(y_test, y_pred)
labels = ["GrippingLeftFaster", "GrippingLeft", "GrippingOnly","GrippingWIthDiffForce"]
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)

disp.plot(cmap=plt.cm.Blues)
plt.show()

